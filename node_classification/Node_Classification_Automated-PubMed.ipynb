{"cells":[{"cell_type":"markdown","metadata":{"id":"aMHjPzMWpDmx"},"source":["### **Exploring the learning task: Node Classification**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44738,"status":"ok","timestamp":1723025101842,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"-BJmYvNULCeS","outputId":"5a7bb653-1d02-4cf7-9b0f-af050e895226"},"outputs":[],"source":["### NOTE: Uncomment below to mount google drive [Only for Colab environment]\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# Define the base path for the runs in this file\n","import os; base_path = os.getcwd() # Define the base path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71217,"status":"ok","timestamp":1723025175654,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"ECZGiVP6LNm7","outputId":"bf2ccde2-6023-4530-f3fd-29e825a33e30"},"outputs":[],"source":["# Install relevant packages for the runs\n","!pip install torch torch-geometric torch-cluster torch-sparse torch-scatter matplotlib networkx"]},{"cell_type":"markdown","metadata":{"id":"FTkG5ta1K91O"},"source":["Experimenting new datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15181,"status":"ok","timestamp":1723025190817,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"r-y2EKGDK91P"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torchvision\n","import torchvision.transforms as transforms\n","from typing import Any\n","import torch_geometric\n","from torch_geometric.data import Dataset as GraphDataset\n","from torch_geometric.loader import DataLoader as GraphDataLoader\n","\n","import os\n","from typing import Tuple\n","import numpy as np\n","import torch\n","from torchvision import transforms\n","from torch_geometric.data import Data\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import random\n","from torch_geometric.utils import to_networkx\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","import os\n","import pickle\n","from copy import deepcopy\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1723025190818,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"fFda2wtOK91R"},"outputs":[],"source":["\"\"\"\n","Helper functions\n","\"\"\"\n","def convert_to_networkx(graph, n_sample=None):\n","    g = to_networkx(graph, node_attrs=[\"x\"])\n","    y = graph.y.numpy()\n","    if n_sample is not None:\n","        sampled_nodes = random.sample(g.nodes, n_sample)\n","        g = g.subgraph(sampled_nodes)\n","        y = y[sampled_nodes]\n","\n","    return g, y\n","\n","\n","def plot_graph(g, y):\n","    plt.figure(figsize=(9, 7))\n","    nx.draw_spring(g, node_size=30, arrows=False, node_color=y)\n","    plt.show()\n","\n","\n","# g, y = convert_to_networkx(graph, n_sample=1000)\n","# plot_graph(g, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1336,"status":"ok","timestamp":1723025192137,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"d5Ao_dzA1o0D"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, ChebConv, GraphConv, SGConv, GENConv, GeneralConv, GATv2Conv, TransformerConv, EGConv\n","\n","\n","# MLP MODEL\n","class MLP(nn.Module):\n","    name = \"MLP\"\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{MLP.name} model init was given bad args\"\n","        self.lin1 = nn.Linear(in_channels, hidden_channels)\n","        self.lin2 = nn.Linear(hidden_channels, out_channels)\n","        self.lin3 = nn.Linear(hidden_channels, out_channels)\n","        self.lin4 = nn.Linear(hidden_channels, out_channels)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.lin1(x)))\n","        output = F.relu(self.lin2(x)) + F.relu(self.lin3(x)) + F.relu(self.lin4(x))\n","\n","        return output\n","\n","# GCN MODEL\n","class GCN(torch.nn.Module):\n","    name = \"GCNConv\"\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{GCN.name} model init was given bad args\"\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, out_channels)\n","        self.conv3 = GCNConv(hidden_channels, out_channels)\n","        self.conv4 = GCNConv(hidden_channels, out_channels)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        output = F.relu(self.conv2(x, edge_index)) + F.relu(self.conv3(x, edge_index)) + F.relu(self.conv4(x, edge_index))\n","\n","        return output\n","\n","# EGCN MODEL\n","class EGCN(torch.nn.Module):\n","    name = \"EGConv\"\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1, num_heads: int = 8, num_bases: int = 4):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{GCN.name} model init was given bad args\"\n","        h_num_heads = num_heads if (hidden_channels % num_heads) == 0 else sys.exit(1) # That's a wrong config\n","        o_num_heads = num_heads if (out_channels % num_heads) == 0 else out_channels\n","        self.conv1 = EGConv(in_channels, hidden_channels, num_heads=h_num_heads, num_bases=h_num_heads // 2)\n","        self.conv2 = EGConv(hidden_channels, out_channels, num_heads=o_num_heads, num_bases=o_num_heads // 2)\n","        self.conv3 = EGConv(hidden_channels, out_channels, num_heads=o_num_heads, num_bases=o_num_heads // 2)\n","        self.conv4 = EGConv(hidden_channels, out_channels, num_heads=o_num_heads, num_bases=o_num_heads // 2)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        output = F.relu(self.conv2(x, edge_index)) + F.relu(self.conv3(x, edge_index)) + F.relu(self.conv4(x, edge_index))\n","\n","        return output\n","\n","\n","# GRAPHCN MODEL\n","class GraphCN(torch.nn.Module):\n","    name = \"GraphConv\"\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{GraphCN.name} model init was given bad args\"\n","        self.conv1 = GraphConv(in_channels, hidden_channels)\n","        self.conv2 = GraphConv(hidden_channels, out_channels)\n","        self.conv3 = GraphConv(hidden_channels, out_channels)\n","        self.conv4 = GraphConv(hidden_channels, out_channels)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        output = F.relu(self.conv2(x, edge_index)) + F.relu(self.conv3(x, edge_index)) + F.relu(self.conv4(x, edge_index))\n","\n","        return output\n","\n","\n","# GENCN MODEL\n","class GenCN(torch.nn.Module):\n","    name = \"GENConv\"\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{GenCN.name} model init was given bad args\"\n","        self.conv1 = GENConv(in_channels, hidden_channels, num_layers=1, bias=True)\n","        self.conv2 = GENConv(hidden_channels, out_channels, num_layers=1, bias=True)\n","        self.conv3 = GENConv(hidden_channels, out_channels, num_layers=1, bias=True)\n","        self.conv4 = GENConv(hidden_channels, out_channels, num_layers=1, bias=True)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        output = F.relu(self.conv2(x, edge_index)) + F.relu(self.conv3(x, edge_index)) + F.relu(self.conv4(x, edge_index))\n","\n","        return output\n","\n","\n","# GeneralCN MODEL\n","# -> Weird issue with running GeneralConv layers on cuda where collect() method has an assertion for non-None edge attributes ;)\n","class GeneralCN(torch.nn.Module):\n","    name = 'GeneralConv'\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{GeneralCN.name} model init was given bad args\"\n","        self.conv1 = GeneralConv(in_channels, hidden_channels, in_edge_channels=1)\n","        self.conv2 = GeneralConv(hidden_channels, out_channels, in_edge_channels=1)\n","        self.conv3 = GeneralConv(hidden_channels, out_channels, in_edge_channels=1)\n","        self.conv4 = GeneralConv(hidden_channels, out_channels, in_edge_channels=1)\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        # Provide a dummy edge attribute (all zeros)\n","        edge_attr = torch.zeros(edge_index.size(1), 1).to(edge_index.device)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index, edge_attr))) # Pass edge_attr to conv layers\n","        output = F.relu(self.conv2(x, edge_index, edge_attr)) + F.relu(self.conv3(x, edge_index, edge_attr)) + F.relu(self.conv4(x, edge_index, edge_attr))\n","\n","        return output\n","\n","\n","# QGRN MODEL\n","import sys; sys.path.append(base_path)\n","from qgrl import QGRL\n","class QGRN(torch.nn.Module):\n","    name = 'QGRL'\n","\n","    def __init__(self, in_channels:int = -1, hidden_channels:int = -1, out_channels:int = -1):\n","        super().__init__()\n","        assert in_channels > 0 and out_channels > 0, f\"{QGRN.name} model init was given bad args\"\n","        self.conv1 = QGRL(\n","                        in_channels=in_channels,\n","                        out_channels=hidden_channels,\n","                        num_sub_kernels=1,\n","                        normalize=False,\n","                        enable_activations=False,\n","                        quant_net_in_features=1,\n","                        quant_net_depth=2,\n","                        quant_net_expansion=1,\n","                        apply_mixture_net=False,\n","                        mixture_net_depth=1,\n","                        mixture_net_expansion=1,\n","                        apply_inner_resd_lyr=False)\n","\n","        self.conv2 = QGRL(\n","                        in_channels=hidden_channels,\n","                        out_channels=out_channels,\n","                        num_sub_kernels=1,\n","                        normalize=False,\n","                        enable_activations=False,\n","                        quant_net_in_features=1,\n","                        quant_net_depth=2,\n","                        quant_net_expansion=1,\n","                        apply_mixture_net=False,\n","                        mixture_net_depth=1,\n","                        mixture_net_expansion=1,\n","                        apply_inner_resd_lyr=False)\n","\n","        self.conv3 = QGRL(\n","                        in_channels=hidden_channels,\n","                        out_channels=out_channels,\n","                        num_sub_kernels=1,\n","                        normalize=False,\n","                        enable_activations=False,\n","                        quant_net_in_features=1,\n","                        quant_net_depth=2,\n","                        quant_net_expansion=1,\n","                        apply_mixture_net=False,\n","                        mixture_net_depth=1,\n","                        mixture_net_expansion=1,\n","                        apply_inner_resd_lyr=False)\n","\n","        self.conv4 = QGRL(\n","                        in_channels=hidden_channels,\n","                        out_channels=out_channels,\n","                        num_sub_kernels=1,\n","                        normalize=False,\n","                        enable_activations=False,\n","                        quant_net_in_features=1,\n","                        quant_net_depth=2,\n","                        quant_net_expansion=1,\n","                        apply_mixture_net=False,\n","                        mixture_net_depth=1,\n","                        mixture_net_expansion=1,\n","                        apply_inner_resd_lyr=False)\n","\n","        self.bn1 = torch.nn.BatchNorm1d(num_features=hidden_channels)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        output = F.relu(self.conv2(x, edge_index)) + F.relu(self.conv3(x, edge_index)) + F.relu(self.conv4(x, edge_index))\n","\n","        return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723025192137,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"Fte1ApHiK91T"},"outputs":[],"source":["# Evaluates a model on a particular graph datasets x model\n","def eval_node_classifier(model, graph, mask):\n","    model.eval()\n","    pred = model(graph).argmax(dim=1)\n","    correct = (pred[mask] == graph.y[mask]).sum()\n","    acc = int(correct) / int(mask.sum())\n","\n","    return acc\n","\n","# Trains a model on a particular graph datasets x model\n","def train_node_classifier(model, graph, optimizer, criterion, n_epochs=200, per_print_interval=10, step=1):\n","    print(f\"\\nStep: {step}\")\n","    test_accs = [] # Assumes an early stopping mechanism\n","    for epoch in range(1, n_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","        out = model(graph)\n","        loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_acc = eval_node_classifier(model, graph, graph.train_mask)\n","        val_acc   = eval_node_classifier(model, graph, graph.val_mask)\n","        if epoch % per_print_interval == 0:\n","            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}')\n","        # Early stopping proxy below\n","        test_accs.append(eval_node_classifier(model, graph, graph.test_mask))\n","\n","    return test_accs\n","\n","# Process the results of the runs\n","def get_summary_of_run_results(results: dict, max_interested_range: int = 20):\n","    from statistics import mean, stdev\n","\n","    summarized = {}\n","    for model_name, model_stats in results.items():\n","        sorted_stats = sorted(model_stats, reverse=True)\n","        trm_stats_range = sorted_stats[:max_interested_range]\n","        stats_min, stats_max, stats_mean, stats_stddev = trm_stats_range[-1], trm_stats_range[0], mean(trm_stats_range), stdev(trm_stats_range)\n","        summarized[model_name] = {\n","                                    \"min\": f'{(stats_min * 100):.2f} %',\n","                                    \"max\": f'{(stats_max * 100):.2f} %',\n","                                    \"eff\": f'{(stats_mean * 100):.2f} ± {(stats_stddev * 100):.2f}'\n","                                   }\n","    return summarized\n","\n","def print_out_summary_results(summary_results: dict):\n","    print(\"\\n=================================================================\")\n","    print(\"Runs for models are summarized below:\")\n","    print(\"=================================================================\")\n","    for model_layer_name, model_stats in summary_results.items():\n","        print(f\"\\nModel: {model_layer_name}\")\n","        for stat_name, stat_value in model_stats.items():\n","            print(f\"\\t {stat_name}: {stat_value}\")\n","\n","\n","\"\"\"\n","Generic Helper function for training models\n","\"\"\"\n","def evaluate_models(models: list,\n","                    dataset:str = 'Cora',\n","                    lrs:list = [0.1, 0.01, 0.001],\n","                    max_epochs:int = 500,\n","                    num_randomizations:int=3,\n","                    d_split:dict={\"num_val\":0.2, \"num_test\":0.2},\n","                    model_hidden_channels: int = 32,\n","                    device:str='cpu:0'):\n","\n","    # Helper to load the dataset with the right split\n","    def get_new_dataset_split(dataset:str = 'Cora'):\n","        # Loading dataset\n","        from torch_geometric.datasets import Planetoid\n","        from torch_geometric.datasets import WikipediaNetwork\n","        from torch_geometric.datasets import Actor\n","        from torch_geometric.datasets import HeterophilousGraphDataset\n","        from torch_geometric.datasets import Amazon, Reddit\n","\n","        graph_dataset = None\n","\n","        if dataset.strip().lower() == 'cora':\n","            graph_dataset = Planetoid(root=f'{base_path}/Datasets/Cora', name='Cora')\n","        elif dataset.strip().lower() == 'citeseer':\n","            graph_dataset = Planetoid(root=f'{base_path}/Datasets/CiteSeer', name='CiteSeer')\n","        elif dataset.strip().lower() == 'pubmed':\n","            graph_dataset = Planetoid(root=f'{base_path}/Datasets/PubMed', name='PubMed')\n","        elif dataset.strip().lower() == 'chameleon':\n","            graph_dataset = WikipediaNetwork(root=f'{base_path}/Datasets/Chameleon', name='Chameleon')\n","        elif dataset.strip().lower() == 'squirrel':\n","            graph_dataset = WikipediaNetwork(root=f'{base_path}/Datasets/Squirrel', name='Squirrel')\n","        elif dataset.strip().lower() == 'film':\n","            graph_dataset = Actor(root=f'{base_path}/Datasets/Film')\n","        elif dataset.strip().lower() == 'roman-empire':\n","            graph_dataset = HeterophilousGraphDataset(root=f'{base_path}/Datasets/RomanEmpire', name='Roman-empire')\n","        elif dataset.strip().lower() == 'amazon-computers':\n","            graph_dataset = Amazon(root=f'{base_path}Datasets/Amazon-Computers', name='Computers')\n","        elif dataset.strip().lower() == 'amazon-photo':\n","            graph_dataset = Amazon(root=f'{base_path}Datasets/Amazon-Photo', name='Photo')\n","        elif dataset.strip().lower() == 'reddit':\n","            graph_dataset = Reddit(root=f'{base_path}Datasets/Reddit')\n","        else:\n","            assert False, f\"Dataset name = {dataset} not supported\"\n","\n","        return graph_dataset\n","\n","    def split_dataset(graph_dataset, num_val:float = 0.2, num_test:float = 0.2):\n","        import torch_geometric.transforms as T\n","        from collections import Counter\n","\n","        graph = T.RandomNodeSplit(num_val=num_val, num_test=num_test)(graph_dataset[0])\n","\n","        print(f\"\\nDataset ({dataset}) stats:\")\n","        print(f\"Number of nodes: {graph_dataset[0].num_nodes}\")\n","        print(f\"Number of edges: {graph_dataset[0].num_edges}\")\n","        print(f\"Number of features: {graph_dataset[0].num_node_features}\")\n","        print(f\"Number of classes: {graph_dataset.num_classes}\")\n","        print(f\"Class Distribution: {Counter(graph.y.tolist()).items()}\")\n","\n","        return graph\n","\n","    # Evaluate the models for the target set of conditions\n","    res = { model.name: [] for model in models }\n","    # load a different split: mimics a k-fold validation\n","    for i in range(num_randomizations):\n","        graph_dataset = get_new_dataset_split(dataset=dataset)\n","        graph = split_dataset(graph_dataset, num_val=d_split[\"num_val\"], num_test=d_split[\"num_test\"]).to(device)\n","        for j, lr in enumerate(lrs):\n","          for k, model in enumerate(models):\n","                mdl = model(in_channels=graph_dataset.num_node_features, hidden_channels=model_hidden_channels, out_channels=graph_dataset.num_classes).to(device)\n","                step = ((i * len(lrs) + j) * len(models)) + k\n","                criterion = nn.CrossEntropyLoss()\n","                optimizer_mdl = torch.optim.Adam(mdl.parameters(), lr=lr)\n","                test_accs = train_node_classifier(mdl, deepcopy(graph), optimizer_mdl, criterion, n_epochs=max_epochs, step=step)\n","                res[model.name].extend(test_accs)\n","\n","                # Save the partial results\n","                results_path = f\"{base_path}/Results\"\n","                if not os.path.exists(results_path): os.mkdir(results_path)\n","                with open(f\"{results_path}/{dataset.strip().lower()}.pk\", \"wb\") as file_handle:\n","                  pickle.dump(res, file_handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # Post process the results\n","    res = { model.name: res[model.name] for model in models }\n","\n","    # Return the results\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxve_5J6K91U","outputId":"0b2923b8-bd6e-463e-eccb-2e13a7831ae6"},"outputs":[],"source":["# Run experiment across Models x Apps\n","results = evaluate_models(models=[QGRN, GraphCN, GenCN, GeneralCN, EGCN],\n","                      dataset='PubMed', # Cora, CiteSeer, PubMed, Squirrel, Chameleon, Amazon-Computers, Amazon-Photo\n","                      lrs=[0.1, 0.05, 0.01, 0.005, 0.001],\n","                      max_epochs=2000,\n","                      num_randomizations=5,\n","                      d_split={\"num_val\":0.2, \"num_test\":0.2},\n","                      model_hidden_channels=64,\n","                      device=str(device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":643,"status":"ok","timestamp":1723025192778,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"nslqe9Q3K91V","outputId":"b91e75ce-d95e-49fc-a930-a2f35e518eca"},"outputs":[],"source":["# # Print out result summary\n","with open(f\"{base_path}/Results/pubmed.pk\", \"rb\") as file_handle:\n","    results = pickle.load(file_handle)\n","print_out_summary_results(get_summary_of_run_results(results, max_interested_range=20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1722893220568,"user":{"displayName":"Grosenick Lab","userId":"04356585480215305325"},"user_tz":420},"id":"1osmmbKwK91W","outputId":"4d614f4c-ad07-4c19-dc2e-88ba9afcc43e"},"outputs":[],"source":["get_summary_of_run_results(results, max_interested_range=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcL5V90UQd3J"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
